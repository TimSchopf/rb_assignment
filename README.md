# GenAI Assignment – Evaluating Generative Agent Simulation Performance

This repository contains the deliverables for a **GenAI assignment** focused on evaluating how accurately generative human simulations mimic real human behavior.

## Project Overview
The task is to assess the performance of LLM-based *human simulations* by comparing their responses to open-ended interview questions against real human answers. The target demographic is **young business professionals with demanding, travel-heavy lifestyles**, relevant for a global Beauty & Wellbeing company.

The evaluation is based on paired responses from:

- Real human participants  
- Corresponding AI-generated human simulations  

## Contents of This Repository
- **/src** – Source code used for the evaluation
- **Technical Report** – Technical report describing methodology, results, and insights
- **Pitch Slide Deck** – CEO-ready pitch deck presenting the evaluation approach and findings

